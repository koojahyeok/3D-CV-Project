{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.lie_group_helper import make_c2w\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  7.9626e-04, -1.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  1.0000e+00,  7.9626e-04,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = make_c2w(torch.tensor([1.57, 0, 0], dtype=torch.float32), torch.tensor([0, 0, 0], dtype=torch.float32))\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43980232, 0.43980232, 0.43980232, 0.64785936])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.transform import Rotation as RotLib\n",
    "\n",
    "\n",
    "def SO3_to_quat(R):\n",
    "    \"\"\"\n",
    "    :param R:  (N, 3, 3) or (3, 3) np\n",
    "    :return:   (N, 4, ) or (4, ) np\n",
    "    \"\"\"\n",
    "    x = RotLib.from_matrix(R)\n",
    "    quat = x.as_quat()\n",
    "    return quat\n",
    "\n",
    "\n",
    "def quat_to_SO3(quat):\n",
    "    \"\"\"\n",
    "    :param quat:    (N, 4, ) or (4, ) np\n",
    "    :return:        (N, 3, 3) or (3, 3) np\n",
    "    \"\"\"\n",
    "    x = RotLib.from_quat(quat)\n",
    "    R = x.as_matrix()\n",
    "    return R\n",
    "\n",
    "\n",
    "def convert3x4_4x4(input):\n",
    "    \"\"\"\n",
    "    :param input:  (N, 3, 4) or (3, 4) torch or np\n",
    "    :return:       (N, 4, 4) or (4, 4) torch or np\n",
    "    \"\"\"\n",
    "    if torch.is_tensor(input):\n",
    "        if len(input.shape) == 3:\n",
    "            output = torch.cat([input, torch.zeros_like(input[:, 0:1])], dim=1)  # (N, 4, 4)\n",
    "            output[:, 3, 3] = 1.0\n",
    "        else:\n",
    "            output = torch.cat([input, torch.tensor([[0,0,0,1]], dtype=input.dtype, device=input.device)], dim=0)  # (4, 4)\n",
    "    else:\n",
    "        if len(input.shape) == 3:\n",
    "            output = np.concatenate([input, np.zeros_like(input[:, 0:1])], axis=1)  # (N, 4, 4)\n",
    "            output[:, 3, 3] = 1.0\n",
    "        else:\n",
    "            output = np.concatenate([input, np.array([[0,0,0,1]], dtype=input.dtype)], axis=0)  # (4, 4)\n",
    "            output[3, 3] = 1.0\n",
    "    return output\n",
    "\n",
    "\n",
    "def vec2skew(v):\n",
    "    \"\"\"\n",
    "    :param v:  (3, ) torch tensor\n",
    "    :return:   (3, 3)\n",
    "    \"\"\"\n",
    "    zero = torch.zeros(1, dtype=torch.float32, device=v.device)\n",
    "    skew_v0 = torch.cat([ zero,    -v[2:3],   v[1:2]])  # (3, 1)\n",
    "    skew_v1 = torch.cat([ v[2:3],   zero,    -v[0:1]])\n",
    "    skew_v2 = torch.cat([-v[1:2],   v[0:1],   zero])\n",
    "    skew_v = torch.stack([skew_v0, skew_v1, skew_v2], dim=0)  # (3, 3)\n",
    "    return skew_v  # (3, 3)\n",
    "\n",
    "\n",
    "def Exp(r):\n",
    "    \"\"\"so(3) vector to SO(3) matrix\n",
    "    :param r: (3, ) axis-angle, torch tensor\n",
    "    :return:  (3, 3)\n",
    "    \"\"\"\n",
    "    skew_r = vec2skew(r)  # (3, 3)\n",
    "    norm_r = r.norm() + 1e-15\n",
    "    eye = torch.eye(3, dtype=torch.float32, device=r.device)\n",
    "    R = eye + (torch.sin(norm_r) / norm_r) * skew_r + ((1 - torch.cos(norm_r)) / norm_r**2) * (skew_r @ skew_r)\n",
    "    return R\n",
    "\n",
    "\n",
    "def make_c2w(r, t):\n",
    "    \"\"\"\n",
    "    :param r:  (3, ) axis-angle             torch tensor\n",
    "    :param t:  (3, ) translation vector     torch tensor\n",
    "    :return:   (4, 4)\n",
    "    \"\"\"\n",
    "    R = Exp(r)  # (3, 3)\n",
    "    c2w = torch.cat([R, t.unsqueeze(1)], dim=1)  # (3, 4)\n",
    "    c2w = convert3x4_4x4(c2w)  # (4, 4)\n",
    "    return c2w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.FloatTensor([1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0., -1.,  1.],\n",
      "        [ 1.,  0., -1.],\n",
      "        [-1.,  1.,  0.]])\n",
      "tensor(1.7321)\n"
     ]
    }
   ],
   "source": [
    "a = torch.FloatTensor([1, 1, 1])\n",
    "r = a\n",
    "\n",
    "skew_r = vec2skew(r)  # (3, 3)\n",
    "print(skew_r)\n",
    "norm_r = r.norm() + 1e-15\n",
    "print(norm_r)\n",
    "eye = torch.eye(3, dtype=torch.float32, device=r.device)\n",
    "R = eye + (torch.sin(norm_r) / norm_r) * skew_r + ((1 - torch.cos(norm_r)) / norm_r**2) * (skew_r @ skew_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_rt(c2w):\n",
    "    \"\"\"\n",
    "    Restores the rotation vector (axis-angle) and translation vector from the c2w matrix\n",
    "    :param c2w: (4, 4) torch tensor\n",
    "    :return:    (3, ) rotation vector, (3, ) translation vector\n",
    "    \"\"\"\n",
    "    R = c2w[:3, :3]  # (3, 3)\n",
    "    t = c2w[:3, 3]   # (3, )\n",
    "\n",
    "    # Convert rotation matrix to axis-angle\n",
    "    rotation_matrix = R.cpu().numpy()  # Convert to numpy for scipy\n",
    "    rot = RotLib.from_matrix(rotation_matrix)\n",
    "    r = torch.tensor(rot.as_rotvec(), dtype=torch.float32, device=c2w.device)  # Convert back to torch tensor\n",
    "\n",
    "    return r, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.intrinsics import LearnFocal\n",
    "model = LearnFocal(H=512, \n",
    "                        W=384, \n",
    "                        n_images=88, \n",
    "                        init_focal=[0 for _ in range(88)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt = torch.load(\"/home/diya/Public/Image2Smiles/KMolOCR_DL_Server/3D-CV-Project/dustnerf/logs/nerfmm/lego/lr_0.001_gpu0_seed_17_resize_1_Nsam_128_Ntr_img_-1_freq_10__240607_2013/latest_focal.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(ckpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 600,\n",
       " 'model_state_dict': OrderedDict([('weight_global',\n",
       "               tensor(0.7835, device='cuda:0')),\n",
       "              ('bias_global', tensor(-101.8961, device='cuda:0')),\n",
       "              ('bias_local',\n",
       "               tensor([ 2.0973e-01, -1.1642e-01,  1.9123e+00,  2.1880e+00, -4.6085e-01,\n",
       "                       -3.8331e+00,  4.3606e-01, -2.6331e+00, -1.7671e+00,  2.6570e+00,\n",
       "                       -3.7215e+00, -2.4732e+00,  2.7677e+00,  1.1785e+00,  1.2484e+00,\n",
       "                       -1.5905e+00, -2.1595e+00,  2.7557e+00,  2.9114e-01,  7.3540e-02,\n",
       "                        4.9491e+00, -4.6179e+00, -1.8507e+00, -8.0863e-01,  9.9891e-01,\n",
       "                        2.6053e-01,  3.1926e+00,  2.0520e+00, -9.4284e+00, -3.3916e+00,\n",
       "                       -3.7549e+00, -2.8690e+00, -4.4767e+00, -2.6130e+00, -1.2340e+01,\n",
       "                        1.3400e+00,  1.5014e+00,  5.1290e-03, -4.9794e+00,  7.5949e+00,\n",
       "                        1.0287e+00,  4.2055e+00, -1.2009e+00,  2.8225e+00,  1.1607e+00,\n",
       "                        4.0261e+00,  2.9057e+00, -3.5951e+00,  2.0994e+00,  8.7555e-02,\n",
       "                       -3.2708e+00, -8.4301e-01, -8.5764e-01, -4.2648e-01,  6.0716e-01,\n",
       "                        3.5516e+00,  2.4569e-01, -2.2354e+00,  5.3312e+00, -3.3259e-01,\n",
       "                        5.5532e-01,  2.1320e+00, -1.4347e+00,  7.6005e-01, -4.1610e-01,\n",
       "                       -2.0810e+00, -5.8663e-01,  2.2216e+00, -6.0879e+00,  1.4032e+00,\n",
       "                       -1.9188e-01, -2.8828e+00,  3.2877e-01, -1.6794e+00,  1.7408e+00,\n",
       "                       -9.2175e+00, -4.3237e+00, -2.4980e+00, -4.3672e+00, -9.5285e+00,\n",
       "                       -7.0116e+00, -4.7558e+00, -4.3636e+00, -6.9078e+00,  4.0133e+00,\n",
       "                        6.7587e+00, -5.5480e-01,  2.5878e+00], device='cuda:0'))]),\n",
       " 'optimizer_state_dict': {'state': {0: {'step': tensor(52888.),\n",
       "    'exp_avg': tensor(0.0199, device='cuda:0'),\n",
       "    'exp_avg_sq': tensor(0.0061, device='cuda:0')},\n",
       "   1: {'step': tensor(52888.),\n",
       "    'exp_avg': tensor(3.4424e-05, device='cuda:0'),\n",
       "    'exp_avg_sq': tensor(8.7690e-09, device='cuda:0')},\n",
       "   2: {'step': tensor(52888.),\n",
       "    'exp_avg': tensor([ 4.0372e-07,  1.1634e-08,  9.2955e-09, -9.1586e-10, -1.9159e-08,\n",
       "            -2.5258e-10, -2.0240e-08,  2.0504e-07,  5.2962e-06,  4.5790e-07,\n",
       "            -8.1672e-08,  1.7985e-09, -6.2580e-08,  2.5973e-09, -6.7833e-09,\n",
       "            -1.2430e-06,  3.0928e-06,  2.1027e-09, -3.8552e-07, -3.4131e-09,\n",
       "            -1.6184e-06,  1.2221e-09, -1.3500e-08,  1.4450e-06, -1.1547e-10,\n",
       "            -3.2491e-07, -1.2789e-06, -1.6606e-06,  7.2111e-09,  2.8254e-09,\n",
       "            -1.3231e-07,  4.3613e-09,  5.7830e-08, -1.2296e-09, -5.1692e-08,\n",
       "             3.0833e-08,  4.9020e-08, -1.0193e-08,  1.0364e-08, -5.3580e-08,\n",
       "            -1.1900e-08,  4.0254e-08,  5.3663e-09,  2.8625e-10,  1.4419e-09,\n",
       "            -3.0783e-09,  6.2760e-10,  1.3274e-08, -6.8554e-09, -2.1753e-07,\n",
       "             2.3689e-10,  3.4584e-09, -4.5046e-07, -2.6065e-08,  1.7009e-06,\n",
       "             4.1985e-08,  1.5143e-07, -1.0607e-06,  3.9122e-09,  3.6152e-08,\n",
       "             7.1725e-07,  6.7991e-08,  6.7276e-07,  3.2273e-06,  2.9699e-06,\n",
       "             1.5279e-09,  1.5226e-05, -8.4144e-09, -3.9900e-10, -1.7072e-09,\n",
       "             7.3052e-09,  3.9334e-07, -2.1744e-08,  5.3309e-08,  9.3195e-07,\n",
       "             1.8349e-07,  9.1688e-09, -7.3559e-08,  1.4006e-06,  1.3696e-07,\n",
       "             2.9342e-10,  7.6518e-08,  1.6305e-09,  2.0847e-07,  4.5031e-10,\n",
       "            -1.1419e-09,  4.0763e-06, -1.7697e-07], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([1.7243e-11, 5.4123e-11, 7.4338e-11, 1.8114e-11, 8.1345e-11, 1.6912e-11,\n",
       "            2.8217e-11, 1.7691e-10, 1.9281e-10, 1.4168e-10, 4.3662e-11, 4.2965e-11,\n",
       "            7.9672e-11, 1.9908e-11, 2.9869e-11, 1.0119e-09, 7.0814e-11, 1.7173e-10,\n",
       "            7.9803e-11, 1.4211e-10, 2.9795e-10, 2.9959e-11, 3.9516e-11, 1.3606e-10,\n",
       "            8.6130e-11, 5.5883e-11, 1.8102e-10, 7.3222e-10, 6.5859e-13, 1.0275e-10,\n",
       "            3.8682e-11, 3.2831e-10, 3.0550e-11, 5.4740e-11, 4.9695e-13, 7.0172e-11,\n",
       "            8.7582e-11, 2.6390e-10, 1.7007e-11, 4.7145e-11, 1.0338e-10, 4.2444e-11,\n",
       "            1.4126e-10, 8.3264e-12, 1.6333e-11, 3.7993e-11, 7.6567e-11, 2.4374e-11,\n",
       "            6.0037e-11, 1.8810e-10, 1.7247e-11, 2.2586e-10, 8.1139e-11, 4.7482e-11,\n",
       "            2.7833e-11, 1.6609e-11, 1.0802e-10, 3.6570e-11, 3.1794e-11, 5.2815e-11,\n",
       "            4.2594e-11, 2.6907e-10, 2.8190e-11, 1.4474e-10, 7.6759e-11, 7.9539e-11,\n",
       "            1.2430e-10, 4.3903e-10, 6.3935e-12, 1.3749e-11, 5.1261e-11, 6.6132e-11,\n",
       "            6.5899e-11, 5.2966e-11, 2.6214e-10, 5.2003e-12, 4.2628e-12, 8.6741e-12,\n",
       "            1.3642e-11, 3.6494e-12, 6.1430e-12, 6.2025e-12, 2.4532e-12, 4.1222e-12,\n",
       "            4.0456e-10, 5.7815e-11, 1.2632e-11, 7.7872e-11], device='cuda:0')}},\n",
       "  'param_groups': [{'lr': 0.004782969000000002,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'initial_lr': 0.01,\n",
       "    'params': [0, 1, 2]}]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-101.8521, -101.8825,  -98.2392,  -97.1087, -101.6837,  -87.2032,\n",
       "         -101.7059,  -94.9630,  -98.7733,  -94.8365,  -88.0468,  -95.7793,\n",
       "          -94.2360, -100.5072, -100.3375,  -99.3664,  -97.2326,  -94.3021,\n",
       "         -101.8113, -101.8907,  -77.4023,  -80.5711,  -98.4708, -101.2422,\n",
       "         -100.8982, -101.8282,  -91.7034,  -97.6853,  -13.0012,  -90.3933,\n",
       "          -87.7967,  -93.6646,  -81.8550,  -95.0682,   50.3814, -100.1005,\n",
       "          -99.6418, -101.8960,  -77.1012,  -44.2137, -100.8379,  -84.2094,\n",
       "         -100.4538,  -93.9297, -100.5489,  -85.6869,  -93.4529,  -88.9712,\n",
       "          -97.4887, -101.8884,  -91.1981, -101.1854, -101.1605, -101.7142,\n",
       "         -101.5274,  -89.2821, -101.8357,  -96.8990,  -73.4749, -101.7855,\n",
       "         -101.5877,  -97.3508,  -99.8376, -101.3184, -101.7229,  -97.5653,\n",
       "         -101.5519,  -96.9606,  -64.8330,  -99.9271, -101.8592,  -93.5854,\n",
       "         -101.7880,  -99.0758,  -98.8656,  -16.9338,  -83.2017,  -95.6560,\n",
       "          -82.8239,  -11.1043,  -52.7339,  -79.2780,  -82.8547,  -54.1790,\n",
       "          -85.7892,  -56.2155, -101.5883,  -95.1996],\n",
       "        [-101.8521, -101.8825,  -98.2392,  -97.1087, -101.6837,  -87.2032,\n",
       "         -101.7059,  -94.9630,  -98.7733,  -94.8365,  -88.0468,  -95.7793,\n",
       "          -94.2360, -100.5072, -100.3375,  -99.3664,  -97.2326,  -94.3021,\n",
       "         -101.8113, -101.8907,  -77.4023,  -80.5711,  -98.4708, -101.2422,\n",
       "         -100.8982, -101.8282,  -91.7034,  -97.6853,  -13.0012,  -90.3933,\n",
       "          -87.7967,  -93.6646,  -81.8550,  -95.0682,   50.3814, -100.1005,\n",
       "          -99.6418, -101.8960,  -77.1012,  -44.2137, -100.8379,  -84.2094,\n",
       "         -100.4538,  -93.9297, -100.5489,  -85.6869,  -93.4529,  -88.9712,\n",
       "          -97.4887, -101.8884,  -91.1981, -101.1854, -101.1605, -101.7142,\n",
       "         -101.5274,  -89.2821, -101.8357,  -96.8990,  -73.4749, -101.7855,\n",
       "         -101.5877,  -97.3508,  -99.8376, -101.3184, -101.7229,  -97.5653,\n",
       "         -101.5519,  -96.9606,  -64.8330,  -99.9271, -101.8592,  -93.5854,\n",
       "         -101.7880,  -99.0758,  -98.8656,  -16.9338,  -83.2017,  -95.6560,\n",
       "          -82.8239,  -11.1043,  -52.7339,  -79.2780,  -82.8547,  -54.1790,\n",
       "          -85.7892,  -56.2155, -101.5883,  -95.1996]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_all_focals()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust3r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
